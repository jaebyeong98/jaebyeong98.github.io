---
layout: post
author: Jaebyeong Jeon
title: "COSA: Context-aware Output-Space Adapter for Test-Time Adaptation in Time Series Forecasting"
tags: [TSF, TTA, ICLR 2026]
---
## Abstract
Deployed time-series forecasters suffer performance degradation under non-stationarity and distribution shifts. Test-time adaptation (TTA) for time-series forecasting differs from vision TTA because ground truth becomes observable shortly after prediction. Existing time-series TTA methods typically employ dual input/output adapters that indirectly modify data distributions, making their effect on the frozen model difficult to analyze. We introduce the Context-aware Output-Space Adapter (COSA), a minimal, plug-and-play adapter that directly corrects predictions of a frozen base model. COSA performs residual correction modulated by gating, utilizing the original prediction and a lightweight context vector that summarizes statistics from recently observed ground truth. At test time, only the adapter parameters (linear layer and gating) are updated under a leakage-free protocol, using observed ground truth with an adaptive learning rate schedule for faster adaptation. Across diverse scenarios, COSA demonstrates substantial performance gains versus baselines without TTA (13.91-17.03%) and SOTA TTA methods (10.48-13.05%), with particularly large improvements at long horizons, while adding a reasonable level of parameters and negligible computational overhead. The simplicity of COSA makes it architecture-agnostic and deployment-friendly.

## COSA: Context-Aware Output-Space Adapter

### Notation and Problem Formulation
- Time series data in real-world have non-stationary property â†’ distributional discrepancy is increasing during test-time

<img src="images/cosa/notation.png" width="500">

### Overall Architecture

<img src="images/cosa/cosa.png" width="600">

- **Key components**
    - A linear layer composed of weight matrix $\mathbf W$ and bias variable $\mathbf b$ that computes correction values $\mathbf H$
    - A learnable gating $\mathbf g$ that controls correction strength
    - A context vector $\mathbf C$ that summarizes and stores recent trend information
- **The streaming protocol for leakage prevention** (let the last adaptation was performed in $t-1$)
    - **Prediction:** At time $t$, base model generates prediction $\mathbf Y^{(0)}_t$ from input $\mathbf X_t$
    - **Correction:** Feed $\mathbf Y_t^{(0)}$ and context $C_t$ into COSA to generate the corrected prediction $\hat {\mathbf Y_t}$
    - **Observation:** After delay $\Delta \geq 0$, values of ground truth of the prediction horizon $\mathbf Y^{true}_t$ are sequentially observed
    - **Adaptation:** Collect the most recent $B$ prediction, ground truth pairs $$\{\hat {\mathbf Y}_{t+i-1}, \mathbf Y^{true}_{t+i-1}\}$$, and perform adaptation that updates COSA parameters $\{\mathbf W,\mathbf b, \mathbf g\}$

### Output-Space Residual Correction

- For time $t$, concatenate the original prediction of base model and context vector to create the adapter input:

$$
\mathbf X_t^{(0)} = [\mathbf Y^{(0)}_t \| \mathbf C_t ].
$$

- The residual is computed using a linear transformation:

$$
\mathbf H_t= \mathbf W \mathbf X_t^{(a)} + \mathbf b.
$$

- The correction magnitude is controlled through gating to compose the final output:

$$
\hat {\mathbf Y}_t = \mathbf Y^{(0)}_t + \text{tanh}(\mathbf g)\mathbf H_t.
$$

### Context Construction

- For time $t$, compute batch-wise aggregation as:

$$
\mu_t=\text{agg}\big \{y^{true}_{t-(kB)+i}: 1\leq i \leq B \big \}, \quad 1\leq k \leq K.
$$

- where the aggregation function $\text {agg}$ can use statistics such as mean, medianm etc
- Construct the context vector by stacking the most recent $K$ aggregated values:

$$
\mathbf C_t = [\mu_1, \mu_2, ..., \mu_K]^\top.
$$

- The context vector summarizes level/scale changes and gradual drift patterns to help interpret the relative magnitude of the base prediction $\mathbf Y^{(0)}_t$

### Adaptation Objective and Scheduling

- Direct objective with weight decay:

$$
\mathcal L = \sum^B_{i=1}\|\hat {\mathbf Y}_{t-i-1} - \mathbf Y^{true}_{t-i-1}\|^2_2 + \lambda (\|\mathbf W\|^2_F+\|\mathbf b\|^2_2 + \|\mathbf g\|^2_2).
$$

- When $B$ forecast-target pairs have been enqueed, run $S$ gradient steps on the adapter parameters using a cosine-adaptive learning-rate schedule, simply *CALR*:

$$
\eta^{(s+1)}=\eta_\text{min}+\frac 1 2 (\eta^{(s)} - \eta _\text{min} ) \big(1+\text{cos} \frac {s\pi} {S}\big)
$$

- Adjust $\eta$ online, based on short-horizon loss trends to encourage fast but stable convergence

<img src="images/cosa/pseudo_code.png" width="500">

## Experiments

<img src="images/cosa/experiment.png" width="600">
